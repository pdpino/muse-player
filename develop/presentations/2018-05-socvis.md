# Presentación socvis

18 mayo 2018

## Esquema

1. Muse
  * BCI
  * Muse
  * Muse + moodplay
  * Desafios
2. EEG data
  * DEAP
  * demo mne



## Hablado

* Portada
  Les voy a presentar sobre el trabajo que he estado haciendo con este aparato llamado Muse, y la integración con la plataforma Moodplay.

* Outline
  La presentación tiene dos partes. Primero, lo que hice el año pasado hasta enero de este año, de trabajar con el Muse. Segundo, lo que estoy empezando a hacer ahora con datos públicos.

* BCI
  - qué es
    Una BCI es una interfaz cerebro-computador. Muy a grandes rasgos, lo que queremos es: desde el cerebro mandar acciones (o sólo actividad cerebral) a un computador, y este puede mandar feedback de vuelta. Esto tiene aplicaciones en muchos ámbitos, por ejemplo en lo que veremos hoy, pero también en personas con alguna discapacidad que puedan aprovechar la tecnología para mover cosas (por ejemplo silla de ruedas).

  - Objetivo
    Todos conocen moodplay?
    Para que tengan en mente durante la presentación, el objetivo inicial es conectar una interfaz BCI con moodplay. Es decir, aportar a la recomendación con un dispositivo BCI.

  - Dos opciones
    Para la integración tenemos dos opciones
    La más simple es detectar el estado mental de la persona y recomendarle según eso. La segunda opción es cambiar su estado mental por medio de recomendaciones sucesivas.

  - fMRI vs EEG
    Para que se hagan una idea, existen varias formas de medir la actividad cerebral. Dos típicas son fMRI y EEG. Son distintas en que fMRI mide potenciales magnéticos y capta cambios en puntos específicos del cerebro. Por otra parte, EEG mide potenciales eléctricos, capta actividad agregada. Las mediciones se hacen con sensores en la superficie, como se muestra acá.

  - Dispositivos EEG
    Existen muchos dispositivos EEG, para uso comercial, para uso en laboratorio. De pocos canales, muchos canales, etc.

* Muse
  - intro
    Entonces: el muse es un dispositivo EEG de uso comercial, viene con una app de celular para meditar. Lo que hacen es detectar qué tan relajado estás y te dan feedback para que medites.
    Tiene 4 canales. Esta es una cabeza mirada desde arriba, los canales son los que están marcados con celeste. O sea tiene 2 canales en la frente y 2 canales detrás de las orejas.
    Es como un cintillo y se coloca en la frente como se ve en la foto. Haremos una demo más adelante.

  - versiones
    Hay dos versiones del dispositivo: 2014 y 2016. La versión 2014 viene con un programa para captar ondas sin escribir código (te permite conectarte, grabar ondas, etc), hecho para investiación, e incluso con una librería para poder captar las cosas en C#. La versión 2016... no tiene nada. A final del año pasado salió una herramienta de visualización, pero está sólo para windows y no es tan buena. Cuando empezamos con esto no había nada, así que tuvimos que partir de 0.

  - software
    Así que el software que he hecho pasa por esto. Tenemos el muse, los datos se manejan con python y se envían procesados a javascript para visualizarse.
    Yo hice una página en javascript que visualiza los datos, pero la gracia es que podemos cambiar esto por el moodplay después.
    En python finalmente encontré un repositorio de un francés que descifró lo básico del bluetooth del muse, así que pude partir de ahí.

  - demo
    Bueno, sin dar más vueltas ahora vamos a pasar a una demo real con el dispositivo.

* Ondas
  - señal es ruidosa
    Señal cruda es ruidosa, así que es útil hacer un análisis de frecuencia de la señal. Alguien sabe sobre procesamiento de señales? Voy a explicar algo muy básico de eso.

  - composición de ondas
    La onda que vemos es suma de ondas de varias frecuencias. Por ejemplo, ahí tenemos dos ondas simples, la de arriba de 4 Hz y baja potencia y la de abajo de 10 Hz y mayor potencia. Si sumamos las ondas, se obtiene esto, que no se entiende mucho. Lo que hacemos entonces es analizar sus frecuencias, representar la onda así: en el eje x está la frecuencia y en el eje y la potencia. Entonces tenemos que esta onda se compone de 2 ondas, justamente una de 4 Hz y otra de 10 Hz, y una de mayor potencia que la otra. Lo que se obtiene de EEG es algo como esto, pero con muchas más ondas sumadas, y lo queremos descomponer

  - fourier
    Tenemos una onda de EEG y la queremos descomponer. Para eso tomamos una ventana y aplicamos una transformación de fourier, que nos da un gráfico como el anterior. Así podemos ver la distribución de frecuencias de esa ventana de la onda.
    La idea ahora es mover la ventana a través de la onda y obtener varios de estos gráficos, y colocarlos de la siguiente manera.

  - fourier 2 (topoplot)
    Se colocan en este plot con 3 dimensiones. En el eje x tenemos el tiempo, en el eje y la frecuencia, y en el eje z (el color) la potencia. Este proceso se conoce como "short-time fast fourier transform". Cómo leer esto: por ejemplo tomamos un rango de frecuencia que nos interese: por ej entre 8 y 18 Hz, y vemos que más o menos en el segundo 25 hubo un aumento de la potencia en esa banda, porque se puso más amarillo.

  - ondas conocidas
    Justamente relacionado, existen estas bandas de frecuencias conocidas, delta, theta, alpha, beta, gamma. Cada una tiene su rango de frecuencias, y se ha estudiado hace muchos años con qué cosas están relacionadas. Por ejemplo si el cerebro tiene mucha actividad en alpha puede estar relajado, en beta concentrado, etc. En el mismo gráfico de antes vemos que hubo un aumento en alpha en el segundo 25, y también un poco en beta.

  - normalización
    Cabe mencionar algo acá. Estamos trabajando con frecuencias, y en general la potencia de las ondas de menor frecuencia es mayor. O sea la potencia baja para frecuencias más altas. Qué pasa con esto? Si tomamos la banda alpha siempre tendrá más potencia que la beta. Entonces, hay que hacer una normalización. Básicamente lo que se hace es tomar un periodo de tiempo de baseline, promediarlo (o mediana) para obtener un valor. Y luego todos los datos dividirlos por eso. Esto debe hacerse por frecuencia.

  - demo 2: ondas
    Pasaremos a una demo.

* Estado mental
  - Mapeo
    Ahora queremos pasar de los datos EEG a otro dominio, a un dominio de estado mental. Queremos con los datos del cerebro decir la emoción del usuario básicamente.

  - opciones mapeo
    Aquí tenemos varias opciones. Una opción es pasar directo al dominio del moodplay, que tiene estas 3 categorías principales de emoción. No es claro cómo hacerlo. Tenemos el modelo valence-arousal, me imagino que la mayoría ya lo conoce. Eje x: emoción positiva o negativa, eje y: activo o pasivo. Y bueno por último se nos ocurrió partir con esta idea más simple, detectar nivel de relajación y concentración, con las ondas conocidas que les mostré antes.

  - fórmula valence-arousal
    Encontramos una fórmula para calcular valence-arousal en un paper, que incluía tomar la onda alpha y beta de dos canales específicos, pero no nos funcionó para nada bien.

  - Dominio relajación-concentración
    Lo que hicimos entonces para empezar fue calcular valores de concentración y reljación y pasarlos a una probabilidad. Qué tan probable es que esté relajado o concentrado. Para calcular la concentración tomamos la onda Beta de los canales de la frente, AF7 y AF8, y promediamos en el rango de frecuencia. Por el lado relajado tomamos los otros dos canales y la onda alpha. Para pasar a porcentaje se usa un softmax.

  - Mapeo moodplay
    Esto hay que mapearlo a moodplay. Lo que hicimos fue bien simple, nuevamente para probar. Tiramos una recta entre sublimity y vitality, hacia sublimity relajación y hacia arriba a la derecha concentración.

  - demo con moodplay
    Pasamos a otra demo

* Desafíos
  Tenemos varios desafíos pendientes en este tema. Los principales son:
  Remover el ruido, como vieron la señal tiene mucho ruido y afecta todos los cálculos.
  Estudiar bien cómo mapear la señal EEG a un dominio de emoción, tenemos algo un poco de juguete hasta ahora, y hay que definir un buen método para usar.
  Integrar la interfaz de usuario con una buena visualización. Hemos pensado
